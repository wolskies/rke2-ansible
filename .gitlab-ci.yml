# SPDX-License-Identifier: GPL-3.0-or-later
# GitLab CI/CD Pipeline for RKE2 Ansible Collection
---
stages:
  - lint
  - unit-test
  - build
  - security-scan
  - deploy-test

variables:
  ANSIBLE_COLLECTIONS_PATH: "${CI_PROJECT_DIR}"
  ANSIBLE_HOST_KEY_CHECKING: "False"
  ANSIBLE_STDOUT_CALLBACK: "yaml"
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  UV_CACHE_DIR: "$CI_PROJECT_DIR/.cache/uv"
  # Self-hosted optimization
  FF_USE_FASTZIP: "true"
  ARTIFACT_COMPRESSION_LEVEL: "fast"
  CACHE_COMPRESSION_LEVEL: "fast"

# Template for common job configuration - optimized for self-hosted
.ansible_job_template: &ansible_job
  image: python:3.13-slim-bookworm
  before_script:
    # Use uv for faster package installation
    - apt update && apt install curl -y
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - source $HOME/.local/bin/env
    - uv venv .venv
    - source .venv/bin/activate
    - uv pip install -r test-requirements.txt
    - |
      # Install collections with retry logic and fallback
      for i in {1..3}; do
        if ansible-galaxy collection install -r requirements.yml --force; then
          echo "Collections installed successfully"
          break
        else
          echo "Attempt $i failed, retrying in 10 seconds..."
          sleep 10
          if [ $i -eq 3 ]; then
            echo "All attempts failed, trying individual collection install"
            ansible-galaxy collection install community.docker --force || \
              echo "WARNING: community.docker install failed"
            ansible-galaxy collection install kubernetes.core --force || \
              echo "WARNING: kubernetes.core install failed"
            ansible-galaxy collection install community.general --force || \
              echo "WARNING: community.general install failed"
          fi
        fi
      done
  cache:
    key:
      files:
        - test-requirements.txt
        - requirements.yml
    paths:
      - .cache/uv/
      - .venv/
      - ~/.ansible/collections/
  tags:
    - docker # Use your self-hosted runners with docker tag

# Linting Stage
lint:ansible-lint:
  <<: *ansible_job
  stage: lint
  script:
    - ansible-lint --version
    # Clean up any existing collections to avoid duplicates
    - rm -rf ansible_collections .ansible 2>/dev/null || true
    # Create ansible-lint config to skip community modules
    - |
      cat > .ansible-lint << 'EOF'
      exclude_paths:
        - .ansible/
        - ansible_collections/
        - .venv/
        - .cache/
      skip_list:
        - var-naming[no-role-prefix]
      warn_list:
        - jinja[spacing]
        - name[template]
      EOF
    - ansible-lint roles/ playbooks/ --format json | tee ansible-lint-report.json
  artifacts:
    reports:
      codequality: ansible-lint-report.json
    when: always
    expire_in: 1 week
  allow_failure: false

lint:yaml:
  <<: *ansible_job
  stage: lint
  script:
    - yamllint --version
    - yamllint -c .yamllint.yml .
  allow_failure: false

# Unit Testing Stage
test:syntax:
  <<: *ansible_job
  stage: unit-test
  before_script:
    # Minimal setup for syntax check only - skip external collections
    - apt update && apt install curl -y
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - source $HOME/.local/bin/env
    - uv venv .venv
    - source .venv/bin/activate
    - uv pip install ansible-core yamllint
  script:
    - |
      for role in roles/*/; do
        echo "Testing syntax for role: $(basename $role)"
        ansible-playbook --syntax-check tests/syntax/test-$(basename $role).yml || exit 1
      done
  parallel:
    matrix:
      - ROLE:
          [
            deploy_rke2,
            helm_install,
            longhorn_install,
            minio_install,
            mysql_operator,
            rancher_install,
            rook_install,
            teardown,
          ]

test:molecule:
  <<: *ansible_job
  stage: unit-test
  services:
    - name: docker:24.0.7-dind
      alias: docker
      command: ["--tls=false", "--host=tcp://0.0.0.0:2375"]
  variables:
    DOCKER_HOST: tcp://docker:2375
    DOCKER_TLS_CERTDIR: ""
  before_script:
    - apt update && apt install curl docker.io -y
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - source $HOME/.local/bin/env
    - uv venv .venv
    - source .venv/bin/activate
    - uv pip install -r test-requirements.txt
    - ansible-galaxy collection install community.docker kubernetes.core community.general --force
  script:
    - echo "Waiting for Docker daemon to start..."
    - timeout 120 sh -c "until docker info >/dev/null 2>&1; do echo 'Connecting to Docker...'; sleep 3; done"
    - docker info
    - |
      roles="deploy_rke2 helm_install longhorn_install minio_install"
      roles="$roles mysql_operator rancher_install rook_install teardown"
      for role in $roles; do
        echo "Testing role: $role"
        cd roles/$role
        molecule test --scenario-name default || true
        cd ../..
      done
  artifacts:
    paths:
      - roles/*/molecule/default/
    when: always
    expire_in: 1 week
  allow_failure: true

# Integration tests skipped - Docker container tests provide limited value
# TODO: Implement Kind-based testing for realistic K8s deployment testing

# Build Stage
build:collection:
  <<: *ansible_job
  stage: build
  script:
    - ansible-galaxy collection build --force
    - ansible-galaxy collection install wolskinet-rke2_ansible-*.tar.gz --force
  artifacts:
    paths:
      - "*.tar.gz"
    expire_in: 1 month
  only:
    - main
    - tags

# Security Scanning Stage
security:ansible-content:
  <<: *ansible_job
  stage: security-scan
  script:
    - pip install ansible-content-scanner
    - ansible-content-scanner scan . > security-report.json || true
  artifacts:
    paths:
      - security-report.json
    when: always
    expire_in: 1 week
  allow_failure: true

security:secrets:
  image: trufflesecurity/trufflehog:latest
  stage: security-scan
  script:
    - trufflehog filesystem --directory=. --json > secrets-scan.json
  artifacts:
    paths:
      - secrets-scan.json
    when: always
    expire_in: 1 week
  allow_failure: true

# Deployment Test Stage
# TODO: Replace with Kind-based testing for realistic K8s cluster deployment
deploy-test:k8s-cluster:
  <<: *ansible_job
  stage: deploy-test
  services:
    - name: docker:24.0.7-dind
      alias: docker
      command: ["--tls=false", "--host=tcp://0.0.0.0:2375"]
  variables:
    DOCKER_HOST: tcp://docker:2375
    DOCKER_TLS_CERTDIR: ""
  before_script:
    - apt update && apt install curl docker.io -y
    - curl -LsSf https://astral.sh/uv/install.sh | sh
    - source $HOME/.local/bin/env
    - uv venv .venv
    - source .venv/bin/activate
    - uv pip install -r test-requirements.txt
    - ansible-galaxy collection install community.docker kubernetes.core community.general --force
  script:
    - echo "Waiting for Docker daemon to start..."
    - timeout 120 sh -c "until docker info >/dev/null 2>&1; do echo 'Connecting to Docker...'; sleep 3; done"
    - docker info
    - cd tests/deployment
    - molecule test --scenario-name k8s-deployment
  artifacts:
    paths:
      - tests/deployment/molecule/k8s-deployment/
      - "**/*.log"
    when: always
    expire_in: 1 week
  only:
    - main
    - tags
  when: manual
